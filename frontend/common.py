import gradio as gr
import os
import json
import random
import shutil
import importlib
from func import functions, model_dl

div_line = "-" * 50

self_dir = os.path.abspath(os.path.dirname(__file__))
workflow_dir = os.path.join(self_dir, 'workflow_files')
config_dir = os.path.join(self_dir, 'config_files')

main_config = functions.load_config(os.path.join(config_dir, 'main_config.yaml'))
model_config = functions.load_config(os.path.join(config_dir, main_config.get('model_config_file')))
model_names = list(model_config.keys())
model_name_a = model_names[0]
resolution_list = model_config[model_name_a].get('resolution_list')

# ä¾‹å­é…ç½®ï¼Œé¡ºä¾¿æŠŠæ ‡é¢˜æ”¾ä¸€èµ·
ex_config = functions.load_config(os.path.join(config_dir, main_config.get('ex_config_file')))
main_name = ex_config.get('main_name')
main_description = ex_config.get('main_description')
main_logo = ex_config.get('main_logo')
examples_dict = ex_config.get('examples_dict')
example_list = list(examples_dict.values())
examples_norm = [t for t in example_list]

WAN_MODELS = ["Wan2.1-T2V-1.3B-480P", "Wan2.1-T2V-14B-720P"]
HUNYUAN_MODELS = ["HunyuanVideo-T2V-720P"]
FLUX_MODELS = ["Flux-T2I-FP16"]

NO_CFG_MODELS = HUNYUAN_MODELS + FLUX_MODELS


KSAMPLER_NAMES = [
    "euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2","dpm_2", "dpm_2_ancestral",
    "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu",
    "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm",
    "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp",
    "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3"
]
SAMPLER_NAMES = KSAMPLER_NAMES + ["ddim", "uni_pc", "uni_pc_bh2"]

# è¿™é‡Œå®šä¹‰ä¸€ä¸‹å«æ³•
if model_name_a in NO_CFG_MODELS:
    cfg_name = 'æ¡ä»¶å¼•å¯¼ç³»æ•°'
    neg_prompt_display = False
else:
    cfg_name = 'CFG'
    neg_prompt_display = True

def img_display(model_name):
    model_type = model_config[model_name].get('model_type')
    if model_type in ["I2V", "I2I"]:
        return True
    else:
        return False
        
input_img_display = img_display(model_name_a)

def clear_outputs():
    return None

def model_switch(model_name=None):
    info_t = f"å·²é€‰æ‹©æ¨¡å‹ {model_name}"
    gr.Info(info_t, duration=3)
    
    resolution_list = model_config[model_name].get('resolution_list')
    input_img_display = img_display(model_name)
    
    return gr.update(choices=resolution_list, value=resolution_list[0]), input_img_display, gr.update(visible=input_img_display)
    # æ›´æ–°ç»™ åˆ†è¾¨ç‡åˆ—è¡¨ã€è¾“å…¥å›¾ç‰‡å­˜å‚¨ã€è¾“å…¥å›¾ç‰‡æ˜¾ç¤ºé¡¹

def seed_update(seed, seed_fixed, all_output):
    if seed_fixed == "ğŸ²" and all_output is not None:
        seed = random.randint(1, 999999999999999)
    return gr.update(value=seed)

def get_workflow(model, scale):
    workflow_file = f'{model}.json'
    workflow_path = os.path.join(workflow_dir, workflow_file) # å·¥ä½œæµæ–‡ä»¶è·¯å¾„
    with open(workflow_path, "r") as f:
        workflow = json.load(f)
    # æ‹†åˆ†æˆå®½å’Œé«˜
    width_str, height_str = scale.split("x")
    width = int(width_str)
    height = int(height_str)
    return workflow, width, height

def edit_workflow(model, prompt_input, neg_prompt_input, scale, steps, cfg, length, batch_size, seed, input_imgs=None, sampler_name=None):
    workflow, width, height = get_workflow(model, scale)
    # print("çœ‹çœ‹é‡‡æ ·å™¨åç§°ï¼š", sampler_name)

    if model in WAN_MODELS:
        workflow["6"]["inputs"]["text"] = prompt_input
        workflow["7"]["inputs"]["text"] = neg_prompt_input
        
        workflow["3"]["inputs"]["steps"] = steps
        workflow["3"]["inputs"]["seed"] = seed
        workflow["3"]["inputs"]["cfg"] = cfg
    
        workflow["40"]["inputs"]["width"] = width
        workflow["40"]["inputs"]["height"] = height
        workflow["40"]["inputs"]["length"] = length
        workflow["40"]["inputs"]["batch_size"] = batch_size
    elif model in HUNYUAN_MODELS:
        workflow["44"]["inputs"]["text"] = prompt_input
        
        workflow["17"]["inputs"]["steps"] = steps
        
        workflow["25"]["inputs"]["noise_seed"] = seed
        workflow["26"]["inputs"]["guidance"] = cfg #
    
        workflow["45"]["inputs"]["width"] = width
        workflow["45"]["inputs"]["height"] = height
        workflow["45"]["inputs"]["length"] = length
        workflow["45"]["inputs"]["batch_size"] = batch_size
    elif model == "LTX-098-I2V-13B":
        workflow["6"]["inputs"]["text"] = prompt_input
        workflow["7"]["inputs"]["text"] = neg_prompt_input
        workflow["71"]["inputs"]["steps"] = steps
        
        workflow["72"]["inputs"]["noise_seed"] = seed
        workflow["72"]["inputs"]["cfg"] = cfg
        
        workflow["95"]["inputs"]["width"] = width
        workflow["95"]["inputs"]["height"] = height
        workflow["95"]["inputs"]["length"] = length
        workflow["95"]["inputs"]["batch_size"] = batch_size

        workflow["78"]["inputs"]["image"] = input_imgs
    # æš‚æ—¶æ²¡æœ‰
    elif model == "LTX-098-T2V-13B":
        workflow["6"]["inputs"]["text"] = prompt_input
        workflow["7"]["inputs"]["text"] = neg_prompt_input
        workflow["71"]["inputs"]["steps"] = steps
        workflow["72"]["inputs"]["noise_seed"] = seed
        workflow["72"]["inputs"]["cfg"] = cfg

        workflow["70"]["inputs"]["width"] = width
        workflow["70"]["inputs"]["height"] = height
        workflow["70"]["inputs"]["length"] = length
        workflow["70"]["inputs"]["batch_size"] = batch_size
    elif model == "Flux-T2I-FP16":
        workflow["6"]["inputs"]["text"] = prompt_input
        workflow["17"]["inputs"]["steps"] = steps
        workflow["25"]["inputs"]["noise_seed"] = seed
        workflow["26"]["inputs"]["guidance"] = cfg
        
        workflow["27"]["inputs"]["width"] = width
        workflow["27"]["inputs"]["height"] = height
        workflow["27"]["inputs"]["batch_size"] = batch_size
        
        workflow["16"]["inputs"]["sampler_name"] = sampler_name

    return workflow



def video_generate(launch_state, img_display_state, model, prompt_input, neg_prompt_input, scale, steps, cfg, length, batch_size, seed, queue_size, input_imgs=None, sampler_name=None):
    from frontend import to_api
    importlib.reload(to_api) # å®æ—¶æ›´æ”¹ç”Ÿæ•ˆï¼Œä»¥åå°±ä¸éœ€è¦äº†

    app_url, back_app_path, dl_way = launch_state
    
    workflow_model_name = model
    if model == "LTX-098-I2V-13B" and input_imgs is None:
        workflow_model_name = "LTX-098-T2V-13B"

    output_dir = os.path.join(os.getcwd(), "outputs")
    os.makedirs(output_dir, exist_ok=True)

    all_output_file_path = []
    model_dl_dict = model_config[model].get('download_way')
    model_dl.check_models(back_app_path, model_dl_dict, dl_way) # æ£€æµ‹æ¨¡å‹
    gr.Info("ä»»åŠ¡å·²æäº¤ï¼Œå¯ä»¥åˆ°åå°æŸ¥çœ‹ä»»åŠ¡è¿›åº¦", duration=10)
    for i in range(queue_size):
        print(f"åˆ—é˜Ÿä»»åŠ¡ï¼š{i+1}/{queue_size}")
        if i > 0:
            seed = random.randint(1, 999999999999999)

        workflow = edit_workflow(workflow_model_name, prompt_input, neg_prompt_input, scale, steps, cfg, length, batch_size, seed, input_imgs, sampler_name)
        
        output_file_path_list = to_api.implement(workflow, app_url, back_app_path)
        # è¦å¤åˆ¶åˆ°å·¥ä½œç›®å½•æ‰è¡Œ
        for generate_file_path in output_file_path_list:
            filename = os.path.basename(generate_file_path)
            target_path = os.path.join(output_dir, filename)
            shutil.copy(generate_file_path, target_path)
            if os.path.exists(target_path):
                print("ç”Ÿæˆæ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š", target_path)
                all_output_file_path.append(target_path)
        print(div_line)
        
    if len(all_output_file_path) > 6:
        tip_inf = f"æç¤ºï¼šæ‰¹é‡ç”Ÿæˆçš„æ•°é‡è¾ƒå¤šï¼Œåªæ˜¾ç¤ºæœ€å 6 ä¸ªï¼Œæ‰€æœ‰ç”Ÿæˆæ–‡ä»¶ï¼Œå¯ä»¥åˆ° {output_dir} ç›®å½•ä¸‹æŸ¥çœ‹"
        gr.Info(tip_inf, duration=3)
        print(tip_inf)
    display_outputs = all_output_file_path[-6:]
    return display_outputs

js_func = """
function refresh() {
    const url = new URL(window.location);

    if (url.searchParams.get('__theme') !== 'dark') {
        url.searchParams.set('__theme', 'dark');
        window.location.href = url.href;
    }
}
"""
# js_func = None

generate_btn_css="""
.custom-btn {
    height: 90px;
    font-size: 18px;
}
"""

# å¦‚æœæ˜¯çƒ­åŠ è½½ï¼Œä¸èƒ½æ”¾ def é‡Œé¢çš„
def gradio_ui(app_url, back_app_path, dl_way):
    
    with gr.Blocks(theme="soft", js=js_func, css=generate_btn_css) as demo:
        gr.HTML(f"""
        <div style="display: flex; align-items: center; justify-content: flex-start; gap: 12px; margin-bottom: 1.5em;">
          <img src={main_logo} 
               alt="Logo" style="height: 48px; auto;">
          <div>
            <div style="font-size: 22px; font-weight: bold;">{main_name}</div>
            <div style="font-size: 14px; color: gray;">{main_description}</div>
          </div>
        </div>
        """)
        with gr.Row():
            with gr.Column(scale=3):
                # gr.Markdown("#### å¯é€‰å‚æ•°")
                model = gr.Dropdown(choices=model_names, label="æ¨¡å‹")
                with gr.Group():
                    scale = gr.Dropdown(choices=resolution_list, label="åˆ†è¾¨ç‡(å®½Ã—é«˜)",)
                    steps = gr.Slider(value=20, label='è¿­ä»£æ­¥æ•° Steps', minimum=1, maximum=128, step=1)
                    cfg = gr.Slider(value=2.5, label=cfg_name, maximum=32, step=0.1)
                    length = gr.Slider(value=97, label='ç”Ÿæˆå¸§æ•°', minimum=25, maximum=1441, step=24, visible=False) # ç”¨ä¸ç€äº†
                    sampler_name = gr.Dropdown(choices=SAMPLER_NAMES, label="é‡‡æ ·å™¨",)
                    batch_size = gr.Slider(value=1, label='å•æ‰¹æ•°é‡', minimum=1, maximum=16, step=1, interactive=True) # ç¦ç”¨å§ , info="å½“å‰æ¨¡å¼ä¸‹æ‰¹æ¬¡å¤§å°ä¸å¯ä¿®æ”¹"
                    
                with gr.Row():
                    seed = gr.Number(value=0, label='éšæœºç§å­ Seed', precision=0, step=1, min_width=140, scale=6)
                    seed_fixed = radio = gr.Radio(choices=["ğŸ“Œ", "ğŸ²"], show_label=False, value="ğŸ²", min_width=20, scale=2)
            with gr.Column(scale=10, min_width=320): # , scale=10
                with gr.Row():
                    # with gr.Column(scale=8):
                    #     with gr.Row():
                    prompt_input = gr.Textbox(
                        label="æç¤ºè¯", placeholder="æ­£å‘æç¤ºè¯ Positive Prompt", show_label=False, container=False, lines=8, max_lines=8, scale=4
                    ) 
                    neg_prompt_input = gr.Textbox(
                        placeholder="åå‘æç¤ºè¯ Negative Prompt", show_label=False,  container=False, lines=8, max_lines=8, scale=4, visible=neg_prompt_display
                    )
    
                    with gr.Column(scale=1, min_width=160): # , min_width=160
                        generate_btn = gr.Button("ç”Ÿ æˆ", variant="primary", elem_classes="custom-btn")
                        gr.Markdown("##### æ‰¹é‡ç”Ÿæˆï¼š")
                        queue_size = gr.Number(value=1, label='åˆ—é˜Ÿæ•°é‡', precision=0, minimum=1, step=1, scale=1, container=False, min_width=126)
                with gr.Column() as examples_container:
                    # å…ˆå ä½ç½®
                    pass
                with gr.Row():
                    input_img = gr.Image(label="ä¸Šä¼ å‚è€ƒå›¾-å¦‚æœä¸ä¸Šä¼ å‚è€ƒå›¾ï¼Œåˆ™é‡‡ç”¨æ–‡ç”Ÿè§†é¢‘æ¨¡å¼", type="filepath", height=432, visible=input_img_display)  # æš‚æ—¶ä¸æ˜¾ç¤ºï¼Œä¹Ÿä¸è°ƒç”¨
                    all_output = gr.Gallery(label="ç”Ÿæˆç»“æœ", columns=3, object_fit="contain", interactive=False, height=432, selected_index=0, preview=True, scale=2)

        with examples_container:
            examples = gr.Examples(label="æç¤ºè¯ç¤ºä¾‹:", examples=examples_norm, inputs=[prompt_input, neg_prompt_input, input_img], example_labels=list(examples_dict.keys()),)
                                    
        launch_state = gr.State(value=(app_url, back_app_path, dl_way)) # å¤šä¸ªå‚æ•°æ”¾è¿™é‡Œæ–¹ä¾¿ä¼ é€’
        img_display_state = gr.State(input_img_display) # ç”¨å®ƒæ¥è®°å½•å§ï¼Œåˆ«ç”¨å…¨å±€ï¼Œå…¶å®æœ€åæ²¡ç”¨åˆ°
        inf = gr.Info()

        clear_outputs_kwargs = {
            "fn": clear_outputs,
            "inputs": [],
            "outputs": [all_output]
        }
        
        generate_kwargs = {
            "fn": video_generate,
            "inputs": [launch_state, img_display_state, model, prompt_input, neg_prompt_input, scale, steps, cfg, length, batch_size, seed, queue_size, input_img] + [sampler_name],
            "outputs": [all_output]
        }
        
        seed_update_kwargs = {
            "fn": seed_update,
            "inputs": [seed, seed_fixed, all_output],
            "outputs": [seed]
        }

        # ç”¨å­—å…¸æ˜¯æ–¹ä¾¿å¾ˆå¤š
        generate_btn.click(**clear_outputs_kwargs).success(**generate_kwargs).success(**seed_update_kwargs)
        model.select(fn=model_switch, inputs=[model], outputs=[scale, img_display_state, input_img])

    return demo

if __name__ == "__main__":
    demo.launch()